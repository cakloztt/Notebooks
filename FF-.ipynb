{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZlrnUA3i3gMB",
        "cellView": "form",
        "collapsed": true,
        "outputId": "3053abdc-b6e2-42b6-e29d-3183474d2789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed!\n"
          ]
        }
      ],
      "source": [
        "#@title Installation\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "import codecs\n",
        "\n",
        "\n",
        "git_repo_rot13 = 'uggcf://tvguho.pbz/snprshfvba/snprshfvba'\n",
        "git_repo = codecs.decode(git_repo_rot13, 'rot 13')\n",
        "\n",
        "#@markdown Choose the branch of  to install: 'master' is the stable latest release, 'next' is the latest beta for in-development features.\n",
        "git_branch =\"master\" #@param [\"master\", \"next\"]\n",
        "\n",
        "\n",
        "if torch.cuda.is_available() and git_branch == \"master\":\n",
        "  !apt-get update\n",
        "  !apt-get install -y nvidia-cuda-toolkit\n",
        "  device=\"cuda\"\n",
        "  print(\"Using GPU\")\n",
        "elif torch.cuda.is_available() and git_branch == \"next\":\n",
        "  # remove cuda 12.2\n",
        "  !apt-get --purge remove \"*cublas*\" \"cuda*\" \"nsight*\" -y\n",
        "  !apt autoremove -y\n",
        "  !apt-get autoclean -y\n",
        "  # download cuda 12.4\n",
        "  !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
        "  !sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "  !wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb\n",
        "  !sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb\n",
        "  !sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
        "  !sudo apt-get update\n",
        "  !sudo apt-get -y install cuda-toolkit-12-4\n",
        "  device=\"cuda\"\n",
        "  print(\"Using GPU\")\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "  print(\"Using CPU\")\n",
        "\n",
        "\n",
        "!git clone $git_repo --branch $git_branch --single-branch\n",
        "\n",
        "directory_rot13 = 'snprshfvba'\n",
        "directory = codecs.decode(directory_rot13, 'rot 13')\n",
        "\n",
        "%cd /content/$directory\n",
        "\n",
        "if device==\"cuda\" and git_branch == \"master\":\n",
        "  !python install.py --onnxruntime cuda-12.2 --skip-conda\n",
        "elif device==\"cuda\" and git_branch == \"next\":\n",
        "  !python install.py --onnxruntime cuda-12.4 --skip-conda\n",
        "elif device == \"cpu\":\n",
        "  !python install.py --onnxruntime default --skip-conda\n",
        "\n",
        "clear_output()\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVHiNI-bb6IA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run UI\n",
        "\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "%cd /content/$directory\n",
        "\n",
        "#@markdown The type of tunnel you wanna use for seeing the public link, so if the API of one of them is down, you can use the other one.\n",
        "Tunnel = \"Gradio\" #@param [\"Gradio\", \"Ngrok\", \"Cloudfare\", \"LocalTunnel\"]\n",
        "\n",
        "#@markdown Also when using Ngrok, Cloudfare or LocalTunnel as the Tunnel, you need to wait for the Local URL to appear, and only after that click on the  Public URL above it.\n",
        "\n",
        "#@markdown Use the option under this only if you chose Ngrok as the Tunnel:\n",
        "\n",
        "#@markdown You can get the Ngrok Tunnel Authtoken here: https://dashboard.ngrok.com/tunnels/authtokens/new.\n",
        "\n",
        "ngrok_tunnel_authtoken = \"Show_1_steps_colab.ipynb\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if Tunnel == \"Gradio\":\n",
        "  file_path_ui_rot13 = \"/pbagrag/snprshfvba/snprshfvba/hvf/ynlbhgf/qrsnhyg.cl\"\n",
        "  file_path_ui = codecs.decode(file_path_ui_rot13, 'rot 13')\n",
        "  !sed -i 's/show_api = False/show_api=False,share=True/g' $file_path_ui\n",
        "elif Tunnel == \"Ngrok\":\n",
        "  !sed -i 's/show_api=False,share=True/show_api = False/g' $file_path_ui\n",
        "  !pip install pyngrok\n",
        "  from pyngrok import ngrok\n",
        "  ngrok.set_auth_token(ngrok_tunnel_authtoken)\n",
        "  http_tunnel = ngrok.connect(7860, bind_tls=True)\n",
        "  clear_output()\n",
        "  print(\"Ngrok Tunnel Public URL:\", http_tunnel.public_url)\n",
        "elif Tunnel == \"Cloudfare\":\n",
        "  !sed -i 's/show_api=False,share=True/show_api = False/g' $file_path_ui\n",
        "  # download cloudfare\n",
        "  !curl -LO https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "  !dpkg -i cloudflared-linux-amd64.deb\n",
        "  !rm -rf nohup.out\n",
        "  import time\n",
        "  # Run cloudflare\n",
        "  !nohup cloudflared tunnel --url localhost:7860 &\n",
        "  clear_output()\n",
        "  time.sleep(5)\n",
        "  # Find and print the Cloudflare URL with a prefix\n",
        "  cloudflare_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\" nohup.out\n",
        "  print(f\"Cloudfare Tunnel Public URL: {cloudflare_url[0]}\")\n",
        "elif Tunnel == \"LocalTunnel\":\n",
        "  !sed -i 's/show_api=False,share=True/show_api = False/g' $file_path_ui\n",
        "  # install\n",
        "  !npm install -g localtunnel\n",
        "  import time\n",
        "  import urllib\n",
        "  # run localtunnel\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 7860 >> url.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  clear_output()\n",
        "  print(f\"LocalTunnel Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  print(f'LocalTunnel Password: {endpoint_ip}')\n",
        "\n",
        "\n",
        "if device==\"cuda\" and git_branch == \"master\":\n",
        "  !python run.py --execution-providers cuda\n",
        "elif device == \"cpu\" and git_branch == \"master\":\n",
        "  !python run.py --execution-providers cpu\n",
        "elif device==\"cuda\" and git_branch == \"next\":\n",
        "  !python $directory\\.py run --execution-providers cuda\n",
        "elif device==\"cpu\" and git_branch == \"next\":\n",
        "  !python $directory\\.py run --execution-providers cpu"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}